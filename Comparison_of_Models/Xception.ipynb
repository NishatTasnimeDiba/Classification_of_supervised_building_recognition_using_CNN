{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-26T14:43:48.329978Z",
     "iopub.status.busy": "2023-09-26T14:43:48.329150Z",
     "iopub.status.idle": "2023-09-26T15:38:03.629313Z",
     "shell.execute_reply": "2023-09-26T15:38:03.626215Z",
     "shell.execute_reply.started": "2023-09-26T14:43:48.329941Z"
    }
   },
   "outputs": [],
   "source": [
    "#\"Model Training\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('/kaggle/input/dataset-ruet/basedata/basedata/training', target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
    "valid_generator = valid_datagen.flow_from_directory('/kaggle/input/dataset-ruet/basedata/basedata/validation', target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('/kaggle/input/dataset-ruet/basedata/basedata/training', target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
    "valid_generator = valid_datagen.flow_from_directory('/kaggle/input/dataset-ruet/basedata/basedata/validation', target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
    "\n",
    "xception_model = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(xception_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator, epochs=50, validation_data=valid_generator)\n",
    "\n",
    "\n",
    "model_dir = '/kaggle/working/model_study/XCEPTION'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model.save(os.path.join(model_dir, 'my_model_Xception.h5'))\n",
    "\n",
    "\n",
    "loss_values = np.array(history.history['loss']).reshape(-1, 1)\n",
    "accuracy_values = np.array(history.history['accuracy']).reshape(-1, 1)\n",
    "val_loss_values = np.array(history.history['val_loss']).reshape(-1, 1)\n",
    "val_accuracy_values = np.array(history.history['val_accuracy']).reshape(-1, 1)\n",
    "\n",
    "file_name = 'RESNETT.csv'\n",
    "\n",
    "results = np.column_stack((loss_values, accuracy_values, val_loss_values, val_accuracy_values))\n",
    "\n",
    "csv_file_path = os.path.join(model_dir,file_name)\n",
    "np.savetxt(csv_file_path, results, delimiter=',', header='Loss,Accuracy,Validation Loss,Validation Accuracy', comments='')\n",
    "\n",
    "print(\"Loss values:\", loss_values)\n",
    "print(\"Accuracy values:\", accuracy_values)\n",
    "print(\"Validation loss values:\", val_loss_values)\n",
    "print(\"Validation accuracy values:\", val_accuracy_values)\n",
    "print(\"CSV file saved at:\", csv_file_path)\n",
    "\n",
    "#\"Testing/Prediction\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import os\n",
    "\n",
    "test_data_dir = '/kaggle/input/dataset-ruet/basedata/basedata/testing'\n",
    "test_images = []\n",
    "ground_truth_labels = []\n",
    "for class_name in os.listdir(test_data_dir):\n",
    "    class_dir = os.path.join(test_data_dir, class_name)\n",
    "    for image_file in os.listdir(class_dir):\n",
    "        image_path = os.path.join(class_dir, image_file)\n",
    "        img = image.load_img(image_path, target_size=(224, 224))  \n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array /= 255.0\n",
    "        test_images.append(img_array)\n",
    "        ground_truth_labels.append(class_name)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "\n",
    "predictions = model.predict(test_images)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "label_to_index = {label: i for i, label in enumerate(train_generator.class_indices)}\n",
    "ground_truth_indices = np.array([label_to_index[label] for label in ground_truth_labels])\n",
    "\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "class_numbers = [label_to_index[label] for label in class_names]\n",
    "\n",
    "conf_matrix = confusion_matrix(ground_truth_indices, predicted_labels)\n",
    "\n",
    "accuracy = accuracy_score(ground_truth_indices, predicted_labels)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap='Blues')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(train_generator.class_indices))\n",
    "plt.xticks(tick_marks, [f\"{class_numbers[i]}: {class_names[i]}\" for i in tick_marks], rotation=45)\n",
    "plt.yticks(tick_marks, [f\"{class_numbers[i]}: {class_names[i]}\" for i in tick_marks])\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('Actual Class')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(loss_values, label='Training Loss')\n",
    "plt.plot(val_loss_values, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(accuracy_values, label='Training Accuracy')\n",
    "plt.plot(val_accuracy_values, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#\"Performance Matrix Calculation\"\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "num_classes = conf_matrix.shape[0]\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "    true_positives = conf_matrix[i, i]\n",
    "    false_positives = np.sum(conf_matrix[:, i]) - true_positives\n",
    "    false_negatives = np.sum(conf_matrix[i, :]) - true_positives\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "    if precision == 0 and recall == 0:\n",
    "        f1_score = 0.0\n",
    "    else:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1_score)\n",
    "\n",
    "print(\"Class Precisions:\", precisions)\n",
    "print(\"Class Recalls:\", recalls)\n",
    "print(\"Class F1 Scores:\", f1_scores)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "micro_precision = precision_score(ground_truth_indices, predicted_labels, average='micro')\n",
    "micro_recall = recall_score(ground_truth_indices, predicted_labels, average='micro')\n",
    "micro_f1 = f1_score(ground_truth_indices, predicted_labels, average='micro')\n",
    "print(\"Micro-Precision:\", micro_precision)\n",
    "print(\"Micro-Recall:\", micro_recall)\n",
    "print(\"Micro-F1:\", micro_f1)\n",
    "\n",
    "top_1_accuracy = accuracy_score(ground_truth_indices, predicted_labels)\n",
    "top_5_predictions = np.argsort(predictions, axis=1)[:, -5:]  \n",
    "top_5_accuracy = np.mean(np.array([ground_truth_indices[i] in top_5_predictions[i] for i in range(len(ground_truth_indices))]))\n",
    "\n",
    "print(\"Top-1 Accuracy:\", top_1_accuracy)\n",
    "print(\"Top-5 Accuracy:\", top_5_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T13:24:46.391966Z",
     "iopub.status.busy": "2023-09-27T13:24:46.391584Z",
     "iopub.status.idle": "2023-09-27T13:25:08.829766Z",
     "shell.execute_reply": "2023-09-27T13:25:08.828766Z",
     "shell.execute_reply.started": "2023-09-27T13:24:46.391936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6355 images belonging to 15 classes.\n",
      "Found 270 images belonging to 15 classes.\n",
      "Found 6355 images belonging to 15 classes.\n",
      "Found 270 images belonging to 15 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83683744/83683744 [==============================] - 4s 0us/step\n",
      "15/15 [==============================] - 7s 97ms/step\n",
      "Confusion Matrix:\n",
      "[[30  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 30  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 30  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0 26  0  0  0  0  0  0  0  0  2  0  0]\n",
      " [ 0  0  0  0 30  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 30  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 30  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 30  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 30  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0 29  0  0  0  0  0]\n",
      " [ 0  0  1  0  3  0  0  0  0  0 24  0  0  2  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0 29  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 30  0  0]\n",
      " [ 0  0  2  0  3  0  0  0  0  0  0  0  0 25  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  2  0  0 27]]\n",
      "Accuracy: 0.9555555555555556\n",
      "Top-1 Accuracy: 0.9555555555555556\n",
      "Top-5 Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#\"Load Model For Testing/Prediction\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('/kaggle/input/dataset-ruet/basedata/basedata/training', target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
    "valid_generator = valid_datagen.flow_from_directory('/kaggle/input/dataset-ruet/basedata/basedata/validation', target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory('/kaggle/input/dataset-ruet/basedata/basedata/training', target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
    "valid_generator = valid_datagen.flow_from_directory('/kaggle/input/dataset-ruet/basedata/basedata/validation', target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
    "\n",
    "xception_model = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(xception_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.load_weights('/kaggle/working/model_study/XCEPTION/my_model_Xception.h5')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import os\n",
    "\n",
    "test_data_dir = '/kaggle/input/dataset-ruet/basedata/basedata/testing'\n",
    "test_images = []\n",
    "ground_truth_labels = []\n",
    "for class_name in os.listdir(test_data_dir):\n",
    "    class_dir = os.path.join(test_data_dir, class_name)\n",
    "    for image_file in os.listdir(class_dir):\n",
    "        image_path = os.path.join(class_dir, image_file)\n",
    "        img = image.load_img(image_path, target_size=(224, 224))  \n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array /= 255.0\n",
    "        test_images.append(img_array)\n",
    "        ground_truth_labels.append(class_name)\n",
    "\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "\n",
    "\n",
    "predictions = model.predict(test_images)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "\n",
    "label_to_index = {label: i for i, label in enumerate(train_generator.class_indices)}\n",
    "ground_truth_indices = np.array([label_to_index[label] for label in ground_truth_labels])\n",
    "\n",
    "\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "class_numbers = [label_to_index[label] for label in class_names]\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(ground_truth_indices, predicted_labels)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(ground_truth_indices, predicted_labels)\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "top_1_accuracy = accuracy_score(ground_truth_indices, predicted_labels)\n",
    "\n",
    "\n",
    "top_5_predictions = np.argsort(predictions, axis=1)[:, -5:]  \n",
    "top_5_accuracy = np.mean(np.array([ground_truth_indices[i] in top_5_predictions[i] for i in range(len(ground_truth_indices))]))\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Top-1 Accuracy:\", top_1_accuracy)\n",
    "print(\"Top-5 Accuracy:\", top_5_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T13:25:44.594925Z",
     "iopub.status.busy": "2023-09-27T13:25:44.594532Z",
     "iopub.status.idle": "2023-09-27T13:25:44.611315Z",
     "shell.execute_reply": "2023-09-27T13:25:44.610109Z",
     "shell.execute_reply.started": "2023-09-27T13:25:44.594889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Metrics:\n",
      "Class 1 - Precision: 0.9090909090909091, Recall: 1.0, F1 Score: 0.9523809523809523, Accuracy: 0.9933333333333333\n",
      "TTP: 30, TTN: 417, TFP: 3, TFN: 0\n",
      "\n",
      "Class 2 - Precision: 1.0, Recall: 1.0, F1 Score: 1.0, Accuracy: 1.0\n",
      "TTP: 30, TTN: 420, TFP: 0, TFN: 0\n",
      "\n",
      "Class 3 - Precision: 0.9090909090909091, Recall: 1.0, F1 Score: 0.9523809523809523, Accuracy: 0.9933333333333333\n",
      "TTP: 30, TTN: 417, TFP: 3, TFN: 0\n",
      "\n",
      "Class 4 - Precision: 1.0, Recall: 0.8666666666666667, F1 Score: 0.9285714285714286, Accuracy: 0.9911111111111112\n",
      "TTP: 26, TTN: 420, TFP: 0, TFN: 4\n",
      "\n",
      "Class 5 - Precision: 0.8108108108108109, Recall: 1.0, F1 Score: 0.8955223880597014, Accuracy: 0.9844444444444445\n",
      "TTP: 30, TTN: 413, TFP: 7, TFN: 0\n",
      "\n",
      "Class 6 - Precision: 1.0, Recall: 1.0, F1 Score: 1.0, Accuracy: 1.0\n",
      "TTP: 30, TTN: 420, TFP: 0, TFN: 0\n",
      "\n",
      "Class 7 - Precision: 1.0, Recall: 1.0, F1 Score: 1.0, Accuracy: 1.0\n",
      "TTP: 30, TTN: 420, TFP: 0, TFN: 0\n",
      "\n",
      "Class 8 - Precision: 0.967741935483871, Recall: 1.0, F1 Score: 0.9836065573770492, Accuracy: 0.9977777777777778\n",
      "TTP: 30, TTN: 419, TFP: 1, TFN: 0\n",
      "\n",
      "Class 9 - Precision: 1.0, Recall: 1.0, F1 Score: 1.0, Accuracy: 1.0\n",
      "TTP: 30, TTN: 420, TFP: 0, TFN: 0\n",
      "\n",
      "Class 10 - Precision: 1.0, Recall: 0.9666666666666667, F1 Score: 0.983050847457627, Accuracy: 0.9977777777777778\n",
      "TTP: 29, TTN: 420, TFP: 0, TFN: 1\n",
      "\n",
      "Class 11 - Precision: 1.0, Recall: 0.8, F1 Score: 0.888888888888889, Accuracy: 0.9866666666666667\n",
      "TTP: 24, TTN: 420, TFP: 0, TFN: 6\n",
      "\n",
      "Class 12 - Precision: 0.9354838709677419, Recall: 0.9666666666666667, F1 Score: 0.9508196721311476, Accuracy: 0.9933333333333333\n",
      "TTP: 29, TTN: 418, TFP: 2, TFN: 1\n",
      "\n",
      "Class 13 - Precision: 0.9375, Recall: 1.0, F1 Score: 0.967741935483871, Accuracy: 0.9955555555555555\n",
      "TTP: 30, TTN: 418, TFP: 2, TFN: 0\n",
      "\n",
      "Class 14 - Precision: 0.9259259259259259, Recall: 0.8333333333333334, F1 Score: 0.8771929824561403, Accuracy: 0.9844444444444445\n",
      "TTP: 25, TTN: 418, TFP: 2, TFN: 5\n",
      "\n",
      "Class 15 - Precision: 1.0, Recall: 0.9, F1 Score: 0.9473684210526316, Accuracy: 0.9933333333333333\n",
      "TTP: 27, TTN: 420, TFP: 0, TFN: 3\n",
      "\n",
      "Average Precision: 0.9597096240913444\n",
      "Average Recall: 0.9555555555555557\n",
      "Average F1 Score: 0.9551683350826926\n",
      "Average Accuracy: 0.994074074074074\n"
     ]
    }
   ],
   "source": [
    "#\"Performance Matrix Calculation\"\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "num_classes = conf_matrix.shape[0]\n",
    "\n",
    "class_metrics = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "    true_positives = conf_matrix[i, i]\n",
    "    false_positives = np.sum(conf_matrix[:, i]) - true_positives\n",
    "    false_negatives = np.sum(conf_matrix[i, :]) - true_positives\n",
    "\n",
    "    true_negatives = np.sum(conf_matrix) - true_positives - false_positives - false_negatives\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "   \n",
    "    if precision == 0 and recall == 0:\n",
    "        f1_score = 0.0\n",
    "    else:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    accuracy = (true_positives + true_negatives) / np.sum(conf_matrix)\n",
    "\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1_score)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    class_metrics.append({\n",
    "        'Class': i + 1,\n",
    "        'True Positives': true_positives,\n",
    "        'True Negatives': true_negatives,\n",
    "        'False Positives': false_positives,\n",
    "        'False Negatives': false_negatives,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1_score,\n",
    "        'Accuracy': accuracy\n",
    "    })\n",
    "\n",
    "average_precision = sum(precisions) / len(precisions)\n",
    "average_recall = sum(recalls) / len(recalls)\n",
    "average_f1_score = sum(f1_scores) / len(f1_scores)\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "print(\"Class Metrics:\")\n",
    "for metrics in class_metrics:\n",
    "    print(f\"Class {metrics['Class']} - Precision: {metrics['Precision']}, Recall: {metrics['Recall']}, F1 Score: {metrics['F1 Score']}, Accuracy: {metrics['Accuracy']}\")\n",
    "    print(f\"TTP: {metrics['True Positives']}, TTN: {metrics['True Negatives']}, TFP: {metrics['False Positives']}, TFN: {metrics['False Negatives']}\")\n",
    "    print(\"\")\n",
    "\n",
    "print(\"Average Precision:\", average_precision)\n",
    "print(\"Average Recall:\", average_recall)\n",
    "print(\"Average F1 Score:\", average_f1_score)\n",
    "print(\"Average Accuracy:\", average_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T13:25:51.892544Z",
     "iopub.status.busy": "2023-09-27T13:25:51.892179Z",
     "iopub.status.idle": "2023-09-27T13:25:51.928499Z",
     "shell.execute_reply": "2023-09-27T13:25:51.927274Z",
     "shell.execute_reply.started": "2023-09-27T13:25:51.892517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Class TTP  TTN TFP TFN  Precision    Recall  F1 Score  Accuracy\n",
      "0          ADMIN  30  417   3   0   0.909091  1.000000  0.952381  0.993333\n",
      "1          ARCHI  30  420   0   0   1.000000  1.000000  1.000000  1.000000\n",
      "2     AUDITORIUM  30  417   3   0   0.909091  1.000000  0.952381  0.993333\n",
      "3    BANGABANDHU  26  420   0   4   1.000000  0.866667  0.928571  0.991111\n",
      "4           CAFE  30  413   7   0   0.810811  1.000000  0.895522  0.984444\n",
      "5     CHIROKUMAR  30  420   0   0   1.000000  1.000000  1.000000  1.000000\n",
      "6          CIVIL  30  420   0   0   1.000000  1.000000  1.000000  1.000000\n",
      "7        CSE DAY  30  419   1   0   0.967742  1.000000  0.983607  0.997778\n",
      "8            EEE  30  420   0   0   1.000000  1.000000  1.000000  1.000000\n",
      "9          HAMID  29  420   0   1   1.000000  0.966667  0.983051  0.997778\n",
      "10       LIBRARY  24  420   0   6   1.000000  0.800000  0.888889  0.986667\n",
      "11      SHAHIDUL  29  418   2   1   0.935484  0.966667  0.950820  0.993333\n",
      "12      TIN SHED  30  418   2   0   0.937500  1.000000  0.967742  0.995556\n",
      "13           URP  25  418   2   5   0.925926  0.833333  0.877193  0.984444\n",
      "14  WELDING SHOP  27  420   0   3   1.000000  0.900000  0.947368  0.993333\n",
      "15       Average                    0.959710  0.955556  0.955168  0.994074\n"
     ]
    }
   ],
   "source": [
    "#\"Results Visualization\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "num_classes = conf_matrix.shape[0]\n",
    "\n",
    "class_names = [\n",
    "    'ADMIN', 'ARCHI', 'AUDITORIUM', 'BANGABANDHU', 'CAFE',\n",
    "    'CHIROKUMAR', 'CIVIL', 'CSE DAY', 'EEE', 'HAMID',\n",
    "    'LIBRARY', 'SHAHIDUL', 'TIN SHED', 'URP', 'WELDING SHOP'\n",
    "]\n",
    "\n",
    "class_metrics = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "    true_positives = conf_matrix[i, i]\n",
    "    false_positives = np.sum(conf_matrix[:, i]) - true_positives\n",
    "    false_negatives = np.sum(conf_matrix[i, :]) - true_positives\n",
    "\n",
    "    true_negatives = np.sum(conf_matrix) - true_positives - false_positives - false_negatives\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "   \n",
    "    if precision == 0 and recall == 0:\n",
    "        f1_score = 0.0\n",
    "    else:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    accuracy = (true_positives + true_negatives) / np.sum(conf_matrix)\n",
    "\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1_score)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    class_metrics.append({\n",
    "        'Class': class_names[i],\n",
    "        'TTP': true_positives,\n",
    "        'TTN': true_negatives,\n",
    "        'TFP': false_positives,\n",
    "        'TFN': false_negatives,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1_score,\n",
    "        'Accuracy': accuracy\n",
    "    })\n",
    "\n",
    "average_precision = sum(precisions) / len(precisions)\n",
    "average_recall = sum(recalls) / len(recalls)\n",
    "average_f1_score = sum(f1_scores) / len(f1_scores)\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "class_metrics.append({\n",
    "    'Class': 'Average',\n",
    "    'TTP': '',  \n",
    "    'TTN': '',\n",
    "    'TFP': '',\n",
    "    'TFN': '',\n",
    "    'Precision': average_precision,\n",
    "    'Recall': average_recall,\n",
    "    'F1 Score': average_f1_score,\n",
    "    'Accuracy': average_accuracy\n",
    "})\n",
    "\n",
    "metrics_df = pd.DataFrame(class_metrics)\n",
    "\n",
    "metrics_df = metrics_df[['Class', 'TTP', 'TTN', 'TFP', 'TFN', 'Precision', 'Recall', 'F1 Score', 'Accuracy']]\n",
    "\n",
    "print(metrics_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
