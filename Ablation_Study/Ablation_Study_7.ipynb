{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-26T17:54:43.327548Z",
     "iopub.status.busy": "2023-09-26T17:54:43.327109Z",
     "iopub.status.idle": "2023-09-26T18:21:15.475870Z",
     "shell.execute_reply": "2023-09-26T18:21:15.474589Z",
     "shell.execute_reply.started": "2023-09-26T17:54:43.327520Z"
    }
   },
   "outputs": [],
   "source": [
    "#\"Model Training\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('/kaggle/input/dataset-ruet/basedata/basedata/training', target_size=(150, 150), batch_size=32, class_mode='categorical')\n",
    "valid_generator = valid_datagen.flow_from_directory('/kaggle/input/dataset-ruet/basedata/basedata/validation', target_size=(150, 150), batch_size=32, class_mode='categorical')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator, epochs=50, validation_data=valid_generator)\n",
    "\n",
    "import os\n",
    "model_dir = '/kaggle/working/model_study/64,128,256 - 512,256,64,15'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "model.save(os.path.join(model_dir, 'my_model_64,128,256 - 512,256,64,15.h5'))\n",
    "\n",
    "loss_values = np.array(history.history['loss']).reshape(-1, 1)\n",
    "accuracy_values = np.array(history.history['accuracy']).reshape(-1, 1)\n",
    "val_loss_values = np.array(history.history['val_loss']).reshape(-1, 1)\n",
    "val_accuracy_values = np.array(history.history['val_accuracy']).reshape(-1, 1)\n",
    "\n",
    "file_name = '64,128,256 - 512,256,64,15.csv'\n",
    "results = np.column_stack((loss_values, accuracy_values, val_loss_values, val_accuracy_values))\n",
    "csv_file_path = os.path.join(model_dir,file_name)\n",
    "np.savetxt(csv_file_path, results, delimiter=',', header='Loss,Accuracy,Validation Loss,Validation Accuracy', comments='')\n",
    "\n",
    "print(\"Loss values:\", loss_values)\n",
    "print(\"Accuracy values:\", accuracy_values)\n",
    "print(\"Validation loss values:\", val_loss_values)\n",
    "print(\"Validation accuracy values:\", val_accuracy_values)\n",
    "print(\"CSV file saved at:\", csv_file_path)\n",
    "\n",
    "\n",
    "#\"Testing/Prediction\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import os\n",
    "\n",
    "test_data_dir = '/kaggle/input/dataset-ruet/basedata/basedata/testing'\n",
    "test_images = []\n",
    "ground_truth_labels = []\n",
    "for class_name in os.listdir(test_data_dir):\n",
    "    class_dir = os.path.join(test_data_dir, class_name)\n",
    "    for image_file in os.listdir(class_dir):\n",
    "        image_path = os.path.join(class_dir, image_file)\n",
    "        img = image.load_img(image_path, target_size=(150, 150))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array /= 255.0\n",
    "        test_images.append(img_array)\n",
    "        ground_truth_labels.append(class_name)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "predictions = model.predict(test_images)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "label_to_index = {label: i for i, label in enumerate(train_generator.class_indices)}\n",
    "ground_truth_indices = np.array([label_to_index[label] for label in ground_truth_labels])\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "class_numbers = [label_to_index[label] for label in class_names]\n",
    "conf_matrix = confusion_matrix(ground_truth_indices, predicted_labels)\n",
    "accuracy = accuracy_score(ground_truth_indices, predicted_labels)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap='Blues')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(train_generator.class_indices))\n",
    "plt.xticks(tick_marks, [f\"{class_numbers[i]}: {class_names[i]}\" for i in tick_marks], rotation=45)\n",
    "plt.yticks(tick_marks, [f\"{class_numbers[i]}: {class_names[i]}\" for i in tick_marks])\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('Actual Class')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(loss_values, label='Training Loss')\n",
    "plt.plot(val_loss_values, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(accuracy_values, label='Training Accuracy')\n",
    "plt.plot(val_accuracy_values, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#\"Performance Matrix Calculation\"\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "num_classes = conf_matrix.shape[0]\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "    true_positives = conf_matrix[i, i]\n",
    "    false_positives = np.sum(conf_matrix[:, i]) - true_positives\n",
    "    false_negatives = np.sum(conf_matrix[i, :]) - true_positives\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "   \n",
    "    if precision == 0 and recall == 0:\n",
    "        f1_score = 0.0\n",
    "    else:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1_score)\n",
    "\n",
    "print(\"Class Precisions:\", precisions)\n",
    "print(\"Class Recalls:\", recalls)\n",
    "print(\"Class F1 Scores:\", f1_scores)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "micro_precision = precision_score(ground_truth_indices, predicted_labels, average='micro')\n",
    "micro_recall = recall_score(ground_truth_indices, predicted_labels, average='micro')\n",
    "micro_f1 = f1_score(ground_truth_indices, predicted_labels, average='micro')\n",
    "print(\"Micro-Precision:\", micro_precision)\n",
    "print(\"Micro-Recall:\", micro_recall)\n",
    "print(\"Micro-F1:\", micro_f1)\n",
    "\n",
    "top_1_accuracy = accuracy_score(ground_truth_indices, predicted_labels)\n",
    "top_5_predictions = np.argsort(predictions, axis=1)[:, -5:]\n",
    "top_5_accuracy = np.mean(np.array([ground_truth_indices[i] in top_5_predictions[i] for i in range(len(ground_truth_indices))]))\n",
    "\n",
    "print(\"Top-1 Accuracy:\", top_1_accuracy)\n",
    "print(\"Top-5 Accuracy:\", top_5_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T13:03:56.094889Z",
     "iopub.status.busy": "2023-09-27T13:03:56.094537Z",
     "iopub.status.idle": "2023-09-27T13:04:07.168541Z",
     "shell.execute_reply": "2023-09-27T13:04:07.167563Z",
     "shell.execute_reply.started": "2023-09-27T13:03:56.094858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6355 images belonging to 15 classes.\n",
      "Found 270 images belonging to 15 classes.\n",
      "15/15 [==============================] - 5s 13ms/step\n",
      "Confusion Matrix:\n",
      "[[23  0  1  0  0  0  1  3  0  0  2  0  0  0  0]\n",
      " [ 0 29  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 28  0  1  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0 30  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 28  0  1  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0 29  0  0  0  0  0  1  0  0  0]\n",
      " [ 1  0  0  0  0  0 26  2  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 30  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  1 28  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 30  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0 29  0  0  0  0]\n",
      " [ 0  0  0  1  1  0  0  0  0  1  0 26  0  0  1]\n",
      " [ 0  0  0  2  0  0  0  0  0  0  1  1 26  0  0]\n",
      " [ 0  0  1  4  1  0  0  0  0  0  2  0  0 22  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 30]]\n",
      "Accuracy: 0.92\n",
      "Top-1 Accuracy: 0.92\n",
      "Top-5 Accuracy: 0.9911111111111112\n"
     ]
    }
   ],
   "source": [
    "#\"Testing/Prediction\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('/kaggle/input/dataset-ruet/basedata/basedata/training', target_size=(150, 150), batch_size=32, class_mode='categorical')\n",
    "valid_generator = valid_datagen.flow_from_directory('/kaggle/input/dataset-ruet/basedata/basedata/validation', target_size=(150, 150), batch_size=32, class_mode='categorical')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.load_weights('/kaggle/working/model_study/64,128,256 - 512,256,64,15/my_model_64,128,256 - 512,256,64,15.h5')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import os\n",
    "\n",
    "test_data_dir = '/kaggle/input/dataset-ruet/basedata/basedata/testing'\n",
    "test_images = []\n",
    "ground_truth_labels = []\n",
    "for class_name in os.listdir(test_data_dir):\n",
    "    class_dir = os.path.join(test_data_dir, class_name)\n",
    "    for image_file in os.listdir(class_dir):\n",
    "        image_path = os.path.join(class_dir, image_file)\n",
    "        img = image.load_img(image_path, target_size=(150, 150))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array /= 255.0\n",
    "        test_images.append(img_array)\n",
    "        ground_truth_labels.append(class_name)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "predictions = model.predict(test_images)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "label_to_index = {label: i for i, label in enumerate(train_generator.class_indices)}\n",
    "ground_truth_indices = np.array([label_to_index[label] for label in ground_truth_labels])\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "class_numbers = [label_to_index[label] for label in class_names]\n",
    "conf_matrix = confusion_matrix(ground_truth_indices, predicted_labels)\n",
    "accuracy = accuracy_score(ground_truth_indices, predicted_labels)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "top_1_accuracy = accuracy_score(ground_truth_indices, predicted_labels)\n",
    "top_5_predictions = np.argsort(predictions, axis=1)[:, -5:]\n",
    "top_5_accuracy = np.mean(np.array([ground_truth_indices[i] in top_5_predictions[i] for i in range(len(ground_truth_indices))]))\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Top-1 Accuracy:\", top_1_accuracy)\n",
    "print(\"Top-5 Accuracy:\", top_5_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T13:04:15.176943Z",
     "iopub.status.busy": "2023-09-27T13:04:15.176566Z",
     "iopub.status.idle": "2023-09-27T13:04:15.193230Z",
     "shell.execute_reply": "2023-09-27T13:04:15.192284Z",
     "shell.execute_reply.started": "2023-09-27T13:04:15.176912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Metrics:\n",
      "Class 1 - Precision: 0.92, Recall: 0.7666666666666667, F1 Score: 0.8363636363636363, Accuracy: 0.98\n",
      "TTP: 23, TTN: 418, TFP: 2, TFN: 7\n",
      "\n",
      "Class 2 - Precision: 1.0, Recall: 0.9666666666666667, F1 Score: 0.983050847457627, Accuracy: 0.9977777777777778\n",
      "TTP: 29, TTN: 420, TFP: 0, TFN: 1\n",
      "\n",
      "Class 3 - Precision: 0.9333333333333333, Recall: 0.9333333333333333, F1 Score: 0.9333333333333333, Accuracy: 0.9911111111111112\n",
      "TTP: 28, TTN: 418, TFP: 2, TFN: 2\n",
      "\n",
      "Class 4 - Precision: 0.8108108108108109, Recall: 1.0, F1 Score: 0.8955223880597014, Accuracy: 0.9844444444444445\n",
      "TTP: 30, TTN: 413, TFP: 7, TFN: 0\n",
      "\n",
      "Class 5 - Precision: 0.9032258064516129, Recall: 0.9333333333333333, F1 Score: 0.9180327868852459, Accuracy: 0.9888888888888889\n",
      "TTP: 28, TTN: 417, TFP: 3, TFN: 2\n",
      "\n",
      "Class 6 - Precision: 1.0, Recall: 0.9666666666666667, F1 Score: 0.983050847457627, Accuracy: 0.9977777777777778\n",
      "TTP: 29, TTN: 420, TFP: 0, TFN: 1\n",
      "\n",
      "Class 7 - Precision: 0.8666666666666667, Recall: 0.8666666666666667, F1 Score: 0.8666666666666667, Accuracy: 0.9822222222222222\n",
      "TTP: 26, TTN: 416, TFP: 4, TFN: 4\n",
      "\n",
      "Class 8 - Precision: 0.8333333333333334, Recall: 1.0, F1 Score: 0.9090909090909091, Accuracy: 0.9866666666666667\n",
      "TTP: 30, TTN: 414, TFP: 6, TFN: 0\n",
      "\n",
      "Class 9 - Precision: 0.9655172413793104, Recall: 0.9333333333333333, F1 Score: 0.9491525423728815, Accuracy: 0.9933333333333333\n",
      "TTP: 28, TTN: 419, TFP: 1, TFN: 2\n",
      "\n",
      "Class 10 - Precision: 0.967741935483871, Recall: 1.0, F1 Score: 0.9836065573770492, Accuracy: 0.9977777777777778\n",
      "TTP: 30, TTN: 419, TFP: 1, TFN: 0\n",
      "\n",
      "Class 11 - Precision: 0.8285714285714286, Recall: 0.9666666666666667, F1 Score: 0.8923076923076922, Accuracy: 0.9844444444444445\n",
      "TTP: 29, TTN: 414, TFP: 6, TFN: 1\n",
      "\n",
      "Class 12 - Precision: 0.9285714285714286, Recall: 0.8666666666666667, F1 Score: 0.896551724137931, Accuracy: 0.9866666666666667\n",
      "TTP: 26, TTN: 418, TFP: 2, TFN: 4\n",
      "\n",
      "Class 13 - Precision: 1.0, Recall: 0.8666666666666667, F1 Score: 0.9285714285714286, Accuracy: 0.9911111111111112\n",
      "TTP: 26, TTN: 420, TFP: 0, TFN: 4\n",
      "\n",
      "Class 14 - Precision: 0.9565217391304348, Recall: 0.7333333333333333, F1 Score: 0.8301886792452831, Accuracy: 0.98\n",
      "TTP: 22, TTN: 419, TFP: 1, TFN: 8\n",
      "\n",
      "Class 15 - Precision: 0.967741935483871, Recall: 1.0, F1 Score: 0.9836065573770492, Accuracy: 0.9977777777777778\n",
      "TTP: 30, TTN: 419, TFP: 1, TFN: 0\n",
      "\n",
      "Average Precision: 0.9254690439477403\n",
      "Average Recall: 0.92\n",
      "Average F1 Score: 0.9192731064469375\n",
      "Average Accuracy: 0.9893333333333332\n"
     ]
    }
   ],
   "source": [
    "#\"Performance Matrix Calculation\"\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "num_classes = conf_matrix.shape[0]\n",
    "\n",
    "class_metrics = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "    true_positives = conf_matrix[i, i]\n",
    "    false_positives = np.sum(conf_matrix[:, i]) - true_positives\n",
    "    false_negatives = np.sum(conf_matrix[i, :]) - true_positives\n",
    "    true_negatives = np.sum(conf_matrix) - true_positives - false_positives - false_negatives\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "   \n",
    "    if precision == 0 and recall == 0:\n",
    "        f1_score = 0.0\n",
    "    else:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    accuracy = (true_positives + true_negatives) / np.sum(conf_matrix)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1_score)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    class_metrics.append({\n",
    "        'Class': i + 1,\n",
    "        'True Positives': true_positives,\n",
    "        'True Negatives': true_negatives,\n",
    "        'False Positives': false_positives,\n",
    "        'False Negatives': false_negatives,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1_score,\n",
    "        'Accuracy': accuracy\n",
    "    })\n",
    "\n",
    "average_precision = sum(precisions) / len(precisions)\n",
    "average_recall = sum(recalls) / len(recalls)\n",
    "average_f1_score = sum(f1_scores) / len(f1_scores)\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "print(\"Class Metrics:\")\n",
    "for metrics in class_metrics:\n",
    "    print(f\"Class {metrics['Class']} - Precision: {metrics['Precision']}, Recall: {metrics['Recall']}, F1 Score: {metrics['F1 Score']}, Accuracy: {metrics['Accuracy']}\")\n",
    "    print(f\"TTP: {metrics['True Positives']}, TTN: {metrics['True Negatives']}, TFP: {metrics['False Positives']}, TFN: {metrics['False Negatives']}\")\n",
    "    print(\"\")\n",
    "\n",
    "print(\"Average Precision:\", average_precision)\n",
    "print(\"Average Recall:\", average_recall)\n",
    "print(\"Average F1 Score:\", average_f1_score)\n",
    "print(\"Average Accuracy:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T13:04:35.824548Z",
     "iopub.status.busy": "2023-09-27T13:04:35.824194Z",
     "iopub.status.idle": "2023-09-27T13:04:35.873162Z",
     "shell.execute_reply": "2023-09-27T13:04:35.872038Z",
     "shell.execute_reply.started": "2023-09-27T13:04:35.824519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Class TTP  TTN TFP TFN  Precision    Recall  F1 Score  Accuracy\n",
      "0          ADMIN  23  418   2   7   0.920000  0.766667  0.836364  0.980000\n",
      "1          ARCHI  29  420   0   1   1.000000  0.966667  0.983051  0.997778\n",
      "2     AUDITORIUM  28  418   2   2   0.933333  0.933333  0.933333  0.991111\n",
      "3    BANGABANDHU  30  413   7   0   0.810811  1.000000  0.895522  0.984444\n",
      "4           CAFE  28  417   3   2   0.903226  0.933333  0.918033  0.988889\n",
      "5     CHIROKUMAR  29  420   0   1   1.000000  0.966667  0.983051  0.997778\n",
      "6          CIVIL  26  416   4   4   0.866667  0.866667  0.866667  0.982222\n",
      "7        CSE DAY  30  414   6   0   0.833333  1.000000  0.909091  0.986667\n",
      "8            EEE  28  419   1   2   0.965517  0.933333  0.949153  0.993333\n",
      "9          HAMID  30  419   1   0   0.967742  1.000000  0.983607  0.997778\n",
      "10       LIBRARY  29  414   6   1   0.828571  0.966667  0.892308  0.984444\n",
      "11      SHAHIDUL  26  418   2   4   0.928571  0.866667  0.896552  0.986667\n",
      "12      TIN SHED  26  420   0   4   1.000000  0.866667  0.928571  0.991111\n",
      "13           URP  22  419   1   8   0.956522  0.733333  0.830189  0.980000\n",
      "14  WELDING SHOP  30  419   1   0   0.967742  1.000000  0.983607  0.997778\n",
      "15       Average                    0.925469  0.920000  0.919273  0.989333\n"
     ]
    }
   ],
   "source": [
    "#\"Results Visualization\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "num_classes = conf_matrix.shape[0]\n",
    "\n",
    "class_names = [\n",
    "    'ADMIN', 'ARCHI', 'AUDITORIUM', 'BANGABANDHU', 'CAFE',\n",
    "    'CHIROKUMAR', 'CIVIL', 'CSE DAY', 'EEE', 'HAMID',\n",
    "    'LIBRARY', 'SHAHIDUL', 'TIN SHED', 'URP', 'WELDING SHOP'\n",
    "]\n",
    "\n",
    "class_metrics = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "    true_positives = conf_matrix[i, i]\n",
    "    false_positives = np.sum(conf_matrix[:, i]) - true_positives\n",
    "    false_negatives = np.sum(conf_matrix[i, :]) - true_positives\n",
    "    true_negatives = np.sum(conf_matrix) - true_positives - false_positives - false_negatives\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "   \n",
    "    if precision == 0 and recall == 0:\n",
    "        f1_score = 0.0\n",
    "    else:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    accuracy = (true_positives + true_negatives) / np.sum(conf_matrix)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1_score)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    class_metrics.append({\n",
    "        'Class': class_names[i],\n",
    "        'TTP': true_positives,\n",
    "        'TTN': true_negatives,\n",
    "        'TFP': false_positives,\n",
    "        'TFN': false_negatives,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1_score,\n",
    "        'Accuracy': accuracy\n",
    "    })\n",
    "\n",
    "average_precision = sum(precisions) / len(precisions)\n",
    "average_recall = sum(recalls) / len(recalls)\n",
    "average_f1_score = sum(f1_scores) / len(f1_scores)\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "class_metrics.append({\n",
    "    'Class': 'Average',\n",
    "    'TTP': '',\n",
    "    'TTN': '',\n",
    "    'TFP': '',\n",
    "    'TFN': '',\n",
    "    'Precision': average_precision,\n",
    "    'Recall': average_recall,\n",
    "    'F1 Score': average_f1_score,\n",
    "    'Accuracy': average_accuracy\n",
    "})\n",
    "\n",
    "metrics_df = pd.DataFrame(class_metrics)\n",
    "metrics_df = metrics_df[['Class', 'TTP', 'TTN', 'TFP', 'TFN', 'Precision', 'Recall', 'F1 Score', 'Accuracy']]\n",
    "\n",
    "print(metrics_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
