{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-26T18:54:31.264626Z",
     "iopub.status.busy": "2023-09-26T18:54:31.264348Z",
     "iopub.status.idle": "2023-09-26T19:22:03.536626Z",
     "shell.execute_reply": "2023-09-26T19:22:03.535433Z",
     "shell.execute_reply.started": "2023-09-26T18:54:31.264601Z"
    }
   },
   "outputs": [],
   "source": [
    "#\"Model Training\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('/kaggle/input/dataset-ruet/basedata/basedata/training', target_size=(150, 150), batch_size=32, class_mode='categorical')\n",
    "valid_generator = valid_datagen.flow_from_directory('/kaggle/input/dataset-ruet/basedata/basedata/validation', target_size=(150, 150), batch_size=32, class_mode='categorical')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu')) \n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator, epochs=50, validation_data=valid_generator)\n",
    "\n",
    "import os\n",
    "model_dir = '/kaggle/working/model_study/32,64,128- 256,128,64,15'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "model.save(os.path.join(model_dir, 'my_model_32,64,128- 256,128,64,15.h5'))\n",
    "\n",
    "loss_values = np.array(history.history['loss']).reshape(-1, 1)\n",
    "accuracy_values = np.array(history.history['accuracy']).reshape(-1, 1)\n",
    "val_loss_values = np.array(history.history['val_loss']).reshape(-1, 1)\n",
    "val_accuracy_values = np.array(history.history['val_accuracy']).reshape(-1, 1)\n",
    "file_name = '32,64,128- 256,128,64,15.csv'\n",
    "\n",
    "results = np.column_stack((loss_values, accuracy_values, val_loss_values, val_accuracy_values))\n",
    "\n",
    "csv_file_path = os.path.join(model_dir,file_name)\n",
    "np.savetxt(csv_file_path, results, delimiter=',', header='Loss,Accuracy,Validation Loss,Validation Accuracy', comments='')\n",
    "\n",
    "print(\"Loss values:\", loss_values)\n",
    "print(\"Accuracy values:\", accuracy_values)\n",
    "print(\"Validation loss values:\", val_loss_values)\n",
    "print(\"Validation accuracy values:\", val_accuracy_values)\n",
    "print(\"CSV file saved at:\", csv_file_path)\n",
    "\n",
    "\n",
    "#\"Testing/Prediction\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import os\n",
    "\n",
    "test_data_dir = '/kaggle/input/dataset-ruet/basedata/basedata/testing'\n",
    "test_images = []\n",
    "ground_truth_labels = []\n",
    "for class_name in os.listdir(test_data_dir):\n",
    "    class_dir = os.path.join(test_data_dir, class_name)\n",
    "    for image_file in os.listdir(class_dir):\n",
    "        image_path = os.path.join(class_dir, image_file)\n",
    "        img = image.load_img(image_path, target_size=(150, 150))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array /= 255.0\n",
    "        test_images.append(img_array)\n",
    "        ground_truth_labels.append(class_name)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "predictions = model.predict(test_images)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "label_to_index = {label: i for i, label in enumerate(train_generator.class_indices)}\n",
    "ground_truth_indices = np.array([label_to_index[label] for label in ground_truth_labels])\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "class_numbers = [label_to_index[label] for label in class_names]\n",
    "conf_matrix = confusion_matrix(ground_truth_indices, predicted_labels)\n",
    "accuracy = accuracy_score(ground_truth_indices, predicted_labels)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap='Blues')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(train_generator.class_indices))\n",
    "plt.xticks(tick_marks, [f\"{class_numbers[i]}: {class_names[i]}\" for i in tick_marks], rotation=45)\n",
    "plt.yticks(tick_marks, [f\"{class_numbers[i]}: {class_names[i]}\" for i in tick_marks])\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('Actual Class')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(loss_values, label='Training Loss')\n",
    "plt.plot(val_loss_values, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(accuracy_values, label='Training Accuracy')\n",
    "plt.plot(val_accuracy_values, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#\"Performance Matrix Calculation\"\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "num_classes = conf_matrix.shape[0]\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "    true_positives = conf_matrix[i, i]\n",
    "    false_positives = np.sum(conf_matrix[:, i]) - true_positives\n",
    "    false_negatives = np.sum(conf_matrix[i, :]) - true_positives\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    \n",
    "    if precision == 0 and recall == 0:\n",
    "        f1_score = 0.0\n",
    "    else:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1_score)\n",
    "\n",
    "print(\"Class Precisions:\", precisions)\n",
    "print(\"Class Recalls:\", recalls)\n",
    "print(\"Class F1 Scores:\", f1_scores)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "micro_precision = precision_score(ground_truth_indices, predicted_labels, average='micro')\n",
    "micro_recall = recall_score(ground_truth_indices, predicted_labels, average='micro')\n",
    "micro_f1 = f1_score(ground_truth_indices, predicted_labels, average='micro')\n",
    "print(\"Micro-Precision:\", micro_precision)\n",
    "print(\"Micro-Recall:\", micro_recall)\n",
    "print(\"Micro-F1:\", micro_f1)\n",
    "\n",
    "top_1_accuracy = accuracy_score(ground_truth_indices, predicted_labels)\n",
    "top_5_predictions = np.argsort(predictions, axis=1)[:, -5:]\n",
    "top_5_accuracy = np.mean(np.array([ground_truth_indices[i] in top_5_predictions[i] for i in range(len(ground_truth_indices))]))\n",
    "\n",
    "print(\"Top-1 Accuracy:\", top_1_accuracy)\n",
    "print(\"Top-5 Accuracy:\", top_5_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T11:29:36.491162Z",
     "iopub.status.busy": "2023-09-27T11:29:36.489911Z",
     "iopub.status.idle": "2023-09-27T11:29:49.063337Z",
     "shell.execute_reply": "2023-09-27T11:29:49.061974Z",
     "shell.execute_reply.started": "2023-09-27T11:29:36.491119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6355 images belonging to 15 classes.\n",
      "Found 270 images belonging to 15 classes.\n",
      "15/15 [==============================] - 4s 232ms/step\n",
      "Confusion Matrix:\n",
      "[[25  2  0  0  0  0  2  0  0  0  1  0  0  0  0]\n",
      " [ 0 24  0  0  0  0  0  3  0  0  1  1  1  0  0]\n",
      " [ 5  0 20  0  1  0  1  0  0  0  2  0  0  1  0]\n",
      " [ 0  1  0 28  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0 22  0  3  2  0  0  2  0  0  0  0]\n",
      " [ 0  0  0  4  0 23  0  0  0  0  1  2  0  0  0]\n",
      " [ 1  0  0  1  0  0 27  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 30  0  0  0  0  0  0  0]\n",
      " [ 0  2  1  0  0  0  3  0 23  0  1  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0 28  0  1  0  0  0]\n",
      " [ 2  0  0  1  0  0  4  0  0  0 23  0  0  0  0]\n",
      " [ 0  1  0  1  0  1  0  0  0  3  1 22  0  1  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  2 27  0  0]\n",
      " [ 3  0  0  3  0  0  1  0  0  0  2  0  1 20  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0 29]]\n",
      "Accuracy: 0.8244444444444444\n",
      "Top-1 Accuracy: 0.8244444444444444\n",
      "Top-5 Accuracy: 0.9844444444444445\n"
     ]
    }
   ],
   "source": [
    "#\"Testing/Prediction\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('/kaggle/input/dataset-ruet/basedata/basedata/training', target_size=(150, 150), batch_size=32, class_mode='categorical')\n",
    "valid_generator = valid_datagen.flow_from_directory('/kaggle/input/dataset-ruet/basedata/basedata/validation', target_size=(150, 150), batch_size=32, class_mode='categorical')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "model.load_weights('/kaggle/working/model_study/32,64,128- 256,128,64,15/my_model_32,64,128- 256,128,64,15.h5')\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import os\n",
    "\n",
    "test_data_dir = '/kaggle/input/dataset-ruet/basedata/basedata/testing'\n",
    "test_images = []\n",
    "ground_truth_labels = []\n",
    "for class_name in os.listdir(test_data_dir):\n",
    "    class_dir = os.path.join(test_data_dir, class_name)\n",
    "    for image_file in os.listdir(class_dir):\n",
    "        image_path = os.path.join(class_dir, image_file)\n",
    "        img = image.load_img(image_path, target_size=(150, 150))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array /= 255.0\n",
    "        test_images.append(img_array)\n",
    "        ground_truth_labels.append(class_name)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "predictions = model.predict(test_images)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "label_to_index = {label: i for i, label in enumerate(train_generator.class_indices)}\n",
    "ground_truth_indices = np.array([label_to_index[label] for label in ground_truth_labels])\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "class_numbers = [label_to_index[label] for label in class_names]\n",
    "conf_matrix = confusion_matrix(ground_truth_indices, predicted_labels)\n",
    "accuracy = accuracy_score(ground_truth_indices, predicted_labels)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "top_1_accuracy = accuracy_score(ground_truth_indices, predicted_labels)\n",
    "top_5_predictions = np.argsort(predictions, axis=1)[:, -5:]\n",
    "top_5_accuracy = np.mean(np.array([ground_truth_indices[i] in top_5_predictions[i] for i in range(len(ground_truth_indices))]))\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Top-1 Accuracy:\", top_1_accuracy)\n",
    "print(\"Top-5 Accuracy:\", top_5_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T11:30:20.751247Z",
     "iopub.status.busy": "2023-09-27T11:30:20.750733Z",
     "iopub.status.idle": "2023-09-27T11:30:20.771577Z",
     "shell.execute_reply": "2023-09-27T11:30:20.770749Z",
     "shell.execute_reply.started": "2023-09-27T11:30:20.751211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Metrics:\n",
      "Class 1 - Precision: 0.6756756756756757, Recall: 0.8333333333333334, F1 Score: 0.746268656716418, Accuracy: 0.9622222222222222\n",
      "TTP: 25, TTN: 408, TFP: 12, TFN: 5\n",
      "\n",
      "Class 2 - Precision: 0.8, Recall: 0.8, F1 Score: 0.8000000000000002, Accuracy: 0.9733333333333334\n",
      "TTP: 24, TTN: 414, TFP: 6, TFN: 6\n",
      "\n",
      "Class 3 - Precision: 0.9523809523809523, Recall: 0.6666666666666666, F1 Score: 0.7843137254901961, Accuracy: 0.9755555555555555\n",
      "TTP: 20, TTN: 419, TFP: 1, TFN: 10\n",
      "\n",
      "Class 4 - Precision: 0.7, Recall: 0.9333333333333333, F1 Score: 0.8, Accuracy: 0.9688888888888889\n",
      "TTP: 28, TTN: 408, TFP: 12, TFN: 2\n",
      "\n",
      "Class 5 - Precision: 0.9565217391304348, Recall: 0.7333333333333333, F1 Score: 0.8301886792452831, Accuracy: 0.98\n",
      "TTP: 22, TTN: 419, TFP: 1, TFN: 8\n",
      "\n",
      "Class 6 - Precision: 0.9583333333333334, Recall: 0.7666666666666667, F1 Score: 0.8518518518518519, Accuracy: 0.9822222222222222\n",
      "TTP: 23, TTN: 419, TFP: 1, TFN: 7\n",
      "\n",
      "Class 7 - Precision: 0.6585365853658537, Recall: 0.9, F1 Score: 0.7605633802816902, Accuracy: 0.9622222222222222\n",
      "TTP: 27, TTN: 406, TFP: 14, TFN: 3\n",
      "\n",
      "Class 8 - Precision: 0.8108108108108109, Recall: 1.0, F1 Score: 0.8955223880597014, Accuracy: 0.9844444444444445\n",
      "TTP: 30, TTN: 413, TFP: 7, TFN: 0\n",
      "\n",
      "Class 9 - Precision: 1.0, Recall: 0.7666666666666667, F1 Score: 0.8679245283018869, Accuracy: 0.9844444444444445\n",
      "TTP: 23, TTN: 420, TFP: 0, TFN: 7\n",
      "\n",
      "Class 10 - Precision: 0.875, Recall: 0.9333333333333333, F1 Score: 0.9032258064516129, Accuracy: 0.9866666666666667\n",
      "TTP: 28, TTN: 416, TFP: 4, TFN: 2\n",
      "\n",
      "Class 11 - Precision: 0.6764705882352942, Recall: 0.7666666666666667, F1 Score: 0.71875, Accuracy: 0.96\n",
      "TTP: 23, TTN: 409, TFP: 11, TFN: 7\n",
      "\n",
      "Class 12 - Precision: 0.7857142857142857, Recall: 0.7333333333333333, F1 Score: 0.7586206896551724, Accuracy: 0.9688888888888889\n",
      "TTP: 22, TTN: 414, TFP: 6, TFN: 8\n",
      "\n",
      "Class 13 - Precision: 0.9310344827586207, Recall: 0.9, F1 Score: 0.9152542372881356, Accuracy: 0.9888888888888889\n",
      "TTP: 27, TTN: 418, TFP: 2, TFN: 3\n",
      "\n",
      "Class 14 - Precision: 0.9090909090909091, Recall: 0.6666666666666666, F1 Score: 0.7692307692307692, Accuracy: 0.9733333333333334\n",
      "TTP: 20, TTN: 418, TFP: 2, TFN: 10\n",
      "\n",
      "Class 15 - Precision: 1.0, Recall: 0.9666666666666667, F1 Score: 0.983050847457627, Accuracy: 0.9977777777777778\n",
      "TTP: 29, TTN: 420, TFP: 0, TFN: 1\n",
      "\n",
      "Average Precision: 0.8459712908330779\n",
      "Average Recall: 0.8244444444444444\n",
      "Average F1 Score: 0.8256510373353562\n",
      "Average Accuracy: 0.9765925925925925\n"
     ]
    }
   ],
   "source": [
    "#\"Performance Matrix Calculation & Visualization\"\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "num_classes = conf_matrix.shape[0]\n",
    "\n",
    "class_metrics = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "    true_positives = conf_matrix[i, i]\n",
    "    false_positives = np.sum(conf_matrix[:, i]) - true_positives\n",
    "    false_negatives = np.sum(conf_matrix[i, :]) - true_positives\n",
    "    true_negatives = np.sum(conf_matrix) - true_positives - false_positives - false_negatives\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "   \n",
    "    if precision == 0 and recall == 0:\n",
    "        f1_score = 0.0\n",
    "    else:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    accuracy = (true_positives + true_negatives) / np.sum(conf_matrix)\n",
    "\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1_score)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    class_metrics.append({\n",
    "        'Class': i + 1,\n",
    "        'True Positives': true_positives,\n",
    "        'True Negatives': true_negatives,\n",
    "        'False Positives': false_positives,\n",
    "        'False Negatives': false_negatives,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1_score,\n",
    "        'Accuracy': accuracy\n",
    "    })\n",
    "\n",
    "average_precision = sum(precisions) / len(precisions)\n",
    "average_recall = sum(recalls) / len(recalls)\n",
    "average_f1_score = sum(f1_scores) / len(f1_scores)\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "print(\"Class Metrics:\")\n",
    "for metrics in class_metrics:\n",
    "    print(f\"Class {metrics['Class']} - Precision: {metrics['Precision']}, Recall: {metrics['Recall']}, F1 Score: {metrics['F1 Score']}, Accuracy: {metrics['Accuracy']}\")\n",
    "    print(f\"TTP: {metrics['True Positives']}, TTN: {metrics['True Negatives']}, TFP: {metrics['False Positives']}, TFN: {metrics['False Negatives']}\")\n",
    "    print(\"\")\n",
    "\n",
    "print(\"Average Precision:\", average_precision)\n",
    "print(\"Average Recall:\", average_recall)\n",
    "print(\"Average F1 Score:\", average_f1_score)\n",
    "print(\"Average Accuracy:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T11:31:07.510680Z",
     "iopub.status.busy": "2023-09-27T11:31:07.510207Z",
     "iopub.status.idle": "2023-09-27T11:31:07.554496Z",
     "shell.execute_reply": "2023-09-27T11:31:07.553026Z",
     "shell.execute_reply.started": "2023-09-27T11:31:07.510646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Class TTP  TTN TFP TFN  Precision    Recall  F1 Score  Accuracy\n",
      "0          ADMIN  25  408  12   5   0.675676  0.833333  0.746269  0.962222\n",
      "1          ARCHI  24  414   6   6   0.800000  0.800000  0.800000  0.973333\n",
      "2     AUDITORIUM  20  419   1  10   0.952381  0.666667  0.784314  0.975556\n",
      "3    BANGABANDHU  28  408  12   2   0.700000  0.933333  0.800000  0.968889\n",
      "4           CAFE  22  419   1   8   0.956522  0.733333  0.830189  0.980000\n",
      "5     CHIROKUMAR  23  419   1   7   0.958333  0.766667  0.851852  0.982222\n",
      "6          CIVIL  27  406  14   3   0.658537  0.900000  0.760563  0.962222\n",
      "7        CSE DAY  30  413   7   0   0.810811  1.000000  0.895522  0.984444\n",
      "8            EEE  23  420   0   7   1.000000  0.766667  0.867925  0.984444\n",
      "9          HAMID  28  416   4   2   0.875000  0.933333  0.903226  0.986667\n",
      "10       LIBRARY  23  409  11   7   0.676471  0.766667  0.718750  0.960000\n",
      "11      SHAHIDUL  22  414   6   8   0.785714  0.733333  0.758621  0.968889\n",
      "12      TIN SHED  27  418   2   3   0.931034  0.900000  0.915254  0.988889\n",
      "13           URP  20  418   2  10   0.909091  0.666667  0.769231  0.973333\n",
      "14  WELDING SHOP  29  420   0   1   1.000000  0.966667  0.983051  0.997778\n",
      "15       Average                    0.845971  0.824444  0.825651  0.976593\n"
     ]
    }
   ],
   "source": [
    "#\"Results Visualization\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "num_classes = conf_matrix.shape[0]\n",
    "\n",
    "class_names = [\n",
    "    'ADMIN', 'ARCHI', 'AUDITORIUM', 'BANGABANDHU', 'CAFE',\n",
    "    'CHIROKUMAR', 'CIVIL', 'CSE DAY', 'EEE', 'HAMID',\n",
    "    'LIBRARY', 'SHAHIDUL', 'TIN SHED', 'URP', 'WELDING SHOP'\n",
    "]\n",
    "\n",
    "class_metrics = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "    true_positives = conf_matrix[i, i]\n",
    "    false_positives = np.sum(conf_matrix[:, i]) - true_positives\n",
    "    false_negatives = np.sum(conf_matrix[i, :]) - true_positives\n",
    "    true_negatives = np.sum(conf_matrix) - true_positives - false_positives - false_negatives\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "   \n",
    "    if precision == 0 and recall == 0:\n",
    "        f1_score = 0.0\n",
    "    else:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    accuracy = (true_positives + true_negatives) / np.sum(conf_matrix)\n",
    "\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1_score)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    class_metrics.append({\n",
    "        'Class': class_names[i],\n",
    "        'TTP': true_positives,\n",
    "        'TTN': true_negatives,\n",
    "        'TFP': false_positives,\n",
    "        'TFN': false_negatives,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1_score,\n",
    "        'Accuracy': accuracy\n",
    "    })\n",
    "\n",
    "average_precision = sum(precisions) / len(precisions)\n",
    "average_recall = sum(recalls) / len(recalls)\n",
    "average_f1_score = sum(f1_scores) / len(f1_scores)\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "class_metrics.append({\n",
    "    'Class': 'Average',\n",
    "    'TTP': '',\n",
    "    'TTN': '',\n",
    "    'TFP': '',\n",
    "    'TFN': '',\n",
    "    'Precision': average_precision,\n",
    "    'Recall': average_recall,\n",
    "    'F1 Score': average_f1_score,\n",
    "    'Accuracy': average_accuracy\n",
    "})\n",
    "\n",
    "metrics_df = pd.DataFrame(class_metrics)\n",
    "metrics_df = metrics_df[['Class', 'TTP', 'TTN', 'TFP', 'TFN', 'Precision', 'Recall', 'F1 Score', 'Accuracy']]\n",
    "\n",
    "print(metrics_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
