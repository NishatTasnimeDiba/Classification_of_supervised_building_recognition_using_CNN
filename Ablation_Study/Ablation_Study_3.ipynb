{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-26T16:13:20.490865Z",
     "iopub.status.busy": "2023-09-26T16:13:20.489971Z",
     "iopub.status.idle": "2023-09-26T16:40:23.675393Z",
     "shell.execute_reply": "2023-09-26T16:40:23.674391Z",
     "shell.execute_reply.started": "2023-09-26T16:13:20.490831Z"
    }
   },
   "outputs": [],
   "source": [
    "#\"Model Training\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('/kaggle/input/dataset-ruet/basedata/basedata/training', target_size=(150, 150), batch_size=32, class_mode='categorical')\n",
    "valid_generator = valid_datagen.flow_from_directory('/kaggle/input/dataset-ruet/basedata/basedata/validation', target_size=(150, 150), batch_size=32, class_mode='categorical')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3))) \n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu')) \n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu')) \n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))  \n",
    "model.add(Dense(256, activation='relu')) \n",
    "model.add(Dense(64, activation='relu')) \n",
    "model.add(Dense(15, activation='softmax')) \n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator, epochs=50, validation_data=valid_generator)\n",
    "\n",
    "import os\n",
    "model_dir = '/kaggle/working/model_study/32,64,128,256 - 512,256,64,15'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "model.save(os.path.join(model_dir, 'my_model_32,64,128,256 - 512,256,64,15.h5'))\n",
    "\n",
    "loss_values = np.array(history.history['loss']).reshape(-1, 1)\n",
    "accuracy_values = np.array(history.history['accuracy']).reshape(-1, 1)\n",
    "val_loss_values = np.array(history.history['val_loss']).reshape(-1, 1)\n",
    "val_accuracy_values = np.array(history.history['val_accuracy']).reshape(-1, 1)\n",
    "\n",
    "file_name = '32,64,128,256 - 512,256,64,15.csv'  \n",
    "\n",
    "results = np.column_stack((loss_values, accuracy_values, val_loss_values, val_accuracy_values))\n",
    "\n",
    "csv_file_path = os.path.join(model_dir,file_name)\n",
    "np.savetxt(csv_file_path, results, delimiter=',', header='Loss,Accuracy,Validation Loss,Validation Accuracy', comments='')\n",
    "\n",
    "print(\"Loss values:\", loss_values)\n",
    "print(\"Accuracy values:\", accuracy_values)\n",
    "print(\"Validation loss values:\", val_loss_values)\n",
    "print(\"Validation accuracy values:\", val_accuracy_values)\n",
    "print(\"CSV file saved at:\", csv_file_path)\n",
    "\n",
    "\n",
    "#\"Testing/Prediction\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import os\n",
    "\n",
    "test_data_dir = '/kaggle/input/dataset-ruet/basedata/basedata/testing'\n",
    "test_images = []\n",
    "ground_truth_labels = []\n",
    "for class_name in os.listdir(test_data_dir):\n",
    "    class_dir = os.path.join(test_data_dir, class_name)\n",
    "    for image_file in os.listdir(class_dir):\n",
    "        image_path = os.path.join(class_dir, image_file)\n",
    "        img = image.load_img(image_path, target_size=(150, 150))  \n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array /= 255.0\n",
    "        test_images.append(img_array)\n",
    "        ground_truth_labels.append(class_name)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "\n",
    "predictions = model.predict(test_images)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "label_to_index = {label: i for i, label in enumerate(train_generator.class_indices)}\n",
    "ground_truth_indices = np.array([label_to_index[label] for label in ground_truth_labels])\n",
    "\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "class_numbers = [label_to_index[label] for label in class_names]\n",
    "\n",
    "conf_matrix = confusion_matrix(ground_truth_indices, predicted_labels)\n",
    "\n",
    "accuracy = accuracy_score(ground_truth_indices, predicted_labels)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap='Blues')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(train_generator.class_indices))\n",
    "plt.xticks(tick_marks, [f\"{class_numbers[i]}: {class_names[i]}\" for i in tick_marks], rotation=45)\n",
    "plt.yticks(tick_marks, [f\"{class_numbers[i]}: {class_names[i]}\" for i in tick_marks])\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('Actual Class')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(loss_values, label='Training Loss')\n",
    "plt.plot(val_loss_values, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(accuracy_values, label='Training Accuracy')\n",
    "plt.plot(val_accuracy_values, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#\"Performance Matrix Calculation\"\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "num_classes = conf_matrix.shape[0]\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "    true_positives = conf_matrix[i, i]\n",
    "    false_positives = np.sum(conf_matrix[:, i]) - true_positives\n",
    "    false_negatives = np.sum(conf_matrix[i, :]) - true_positives\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "    if precision == 0 and recall == 0:\n",
    "        f1_score = 0.0\n",
    "    else:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1_score)\n",
    "\n",
    "print(\"Class Precisions:\", precisions)\n",
    "print(\"Class Recalls:\", recalls)\n",
    "print(\"Class F1 Scores:\", f1_scores)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "micro_precision = precision_score(ground_truth_indices, predicted_labels, average='micro')\n",
    "micro_recall = recall_score(ground_truth_indices, predicted_labels, average='micro')\n",
    "micro_f1 = f1_score(ground_truth_indices, predicted_labels, average='micro')\n",
    "print(\"Micro-Precision:\", micro_precision)\n",
    "print(\"Micro-Recall:\", micro_recall)\n",
    "print(\"Micro-F1:\", micro_f1)\n",
    "\n",
    "top_1_accuracy = accuracy_score(ground_truth_indices, predicted_labels)\n",
    "top_5_predictions = np.argsort(predictions, axis=1)[:, -5:] \n",
    "top_5_accuracy = np.mean(np.array([ground_truth_indices[i] in top_5_predictions[i] for i in range(len(ground_truth_indices))]))\n",
    "\n",
    "print(\"Top-1 Accuracy:\", top_1_accuracy)\n",
    "print(\"Top-5 Accuracy:\", top_5_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T13:10:35.316403Z",
     "iopub.status.busy": "2023-09-27T13:10:35.315949Z",
     "iopub.status.idle": "2023-09-27T13:10:57.225512Z",
     "shell.execute_reply": "2023-09-27T13:10:57.224250Z",
     "shell.execute_reply.started": "2023-09-27T13:10:35.316369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6355 images belonging to 15 classes.\n",
      "Found 270 images belonging to 15 classes.\n",
      "15/15 [==============================] - 6s 14ms/step\n",
      "Confusion Matrix:\n",
      "[[23  0  1  0  0  0  1  2  0  2  0  0  1  0  0]\n",
      " [ 0 30  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  0 26  0  0  0  0  0  0  0  0  0  0  2  0]\n",
      " [ 0  0  0 30  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 27  0  2  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 30  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 28  1  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 30  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1 29  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 30  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  1  0  0 28  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0  0  0  1  0 26  0  0  1]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0 29  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0 29  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0 29]]\n",
      "Accuracy: 0.9422222222222222\n",
      "Top-1 Accuracy: 0.9422222222222222\n",
      "Top-5 Accuracy: 0.9977777777777778\n"
     ]
    }
   ],
   "source": [
    "#\"Testing/Prediction\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('/kaggle/input/dataset-ruet/basedata/basedata/training', target_size=(150, 150), batch_size=32, class_mode='categorical')\n",
    "valid_generator = valid_datagen.flow_from_directory('/kaggle/input/dataset-ruet/basedata/basedata/validation', target_size=(150, 150), batch_size=32, class_mode='categorical')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(15, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.load_weights('/kaggle/working/model_study/32,64,128,256 - 512,256,64,15/my_model_32,64,128,256 - 512,256,64,15.h5')\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import os\n",
    "\n",
    "test_data_dir = '/kaggle/input/dataset-ruet/basedata/basedata/testing'\n",
    "test_images = []\n",
    "ground_truth_labels = []\n",
    "for class_name in os.listdir(test_data_dir):\n",
    "    class_dir = os.path.join(test_data_dir, class_name)\n",
    "    for image_file in os.listdir(class_dir):\n",
    "        image_path = os.path.join(class_dir, image_file)\n",
    "        img = image.load_img(image_path, target_size=(150, 150))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array /= 255.0\n",
    "        test_images.append(img_array)\n",
    "        ground_truth_labels.append(class_name)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "\n",
    "predictions = model.predict(test_images)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "label_to_index = {label: i for i, label in enumerate(train_generator.class_indices)}\n",
    "ground_truth_indices = np.array([label_to_index[label] for label in ground_truth_labels])\n",
    "\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "class_numbers = [label_to_index[label] for label in class_names]\n",
    "\n",
    "conf_matrix = confusion_matrix(ground_truth_indices, predicted_labels)\n",
    "\n",
    "accuracy = accuracy_score(ground_truth_indices, predicted_labels)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "top_1_accuracy = accuracy_score(ground_truth_indices, predicted_labels)\n",
    "\n",
    "top_5_predictions = np.argsort(predictions, axis=1)[:, -5:]\n",
    "top_5_accuracy = np.mean(np.array([ground_truth_indices[i] in top_5_predictions[i] for i in range(len(ground_truth_indices))]))\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Top-1 Accuracy:\", top_1_accuracy)\n",
    "print(\"Top-5 Accuracy:\", top_5_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T13:11:04.201466Z",
     "iopub.status.busy": "2023-09-27T13:11:04.200936Z",
     "iopub.status.idle": "2023-09-27T13:11:04.223601Z",
     "shell.execute_reply": "2023-09-27T13:11:04.222495Z",
     "shell.execute_reply.started": "2023-09-27T13:11:04.201423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Metrics:\n",
      "Class 1 - Precision: 0.92, Recall: 0.7666666666666667, F1 Score: 0.8363636363636363, Accuracy: 0.98\n",
      "TTP: 23, TTN: 418, TFP: 2, TFN: 7\n",
      "\n",
      "Class 2 - Precision: 1.0, Recall: 1.0, F1 Score: 1.0, Accuracy: 1.0\n",
      "TTP: 30, TTN: 420, TFP: 0, TFN: 0\n",
      "\n",
      "Class 3 - Precision: 0.9629629629629629, Recall: 0.8666666666666667, F1 Score: 0.912280701754386, Accuracy: 0.9888888888888889\n",
      "TTP: 26, TTN: 419, TFP: 1, TFN: 4\n",
      "\n",
      "Class 4 - Precision: 0.9090909090909091, Recall: 1.0, F1 Score: 0.9523809523809523, Accuracy: 0.9933333333333333\n",
      "TTP: 30, TTN: 417, TFP: 3, TFN: 0\n",
      "\n",
      "Class 5 - Precision: 1.0, Recall: 0.9, F1 Score: 0.9473684210526316, Accuracy: 0.9933333333333333\n",
      "TTP: 27, TTN: 420, TFP: 0, TFN: 3\n",
      "\n",
      "Class 6 - Precision: 1.0, Recall: 1.0, F1 Score: 1.0, Accuracy: 1.0\n",
      "TTP: 30, TTN: 420, TFP: 0, TFN: 0\n",
      "\n",
      "Class 7 - Precision: 0.875, Recall: 0.9333333333333333, F1 Score: 0.9032258064516129, Accuracy: 0.9866666666666667\n",
      "TTP: 28, TTN: 416, TFP: 4, TFN: 2\n",
      "\n",
      "Class 8 - Precision: 0.8571428571428571, Recall: 1.0, F1 Score: 0.923076923076923, Accuracy: 0.9888888888888889\n",
      "TTP: 30, TTN: 415, TFP: 5, TFN: 0\n",
      "\n",
      "Class 9 - Precision: 0.9666666666666667, Recall: 0.9666666666666667, F1 Score: 0.9666666666666667, Accuracy: 0.9955555555555555\n",
      "TTP: 29, TTN: 419, TFP: 1, TFN: 1\n",
      "\n",
      "Class 10 - Precision: 0.8823529411764706, Recall: 1.0, F1 Score: 0.9375, Accuracy: 0.9911111111111112\n",
      "TTP: 30, TTN: 416, TFP: 4, TFN: 0\n",
      "\n",
      "Class 11 - Precision: 0.9655172413793104, Recall: 0.9333333333333333, F1 Score: 0.9491525423728815, Accuracy: 0.9933333333333333\n",
      "TTP: 28, TTN: 419, TFP: 1, TFN: 2\n",
      "\n",
      "Class 12 - Precision: 0.9629629629629629, Recall: 0.8666666666666667, F1 Score: 0.912280701754386, Accuracy: 0.9888888888888889\n",
      "TTP: 26, TTN: 419, TFP: 1, TFN: 4\n",
      "\n",
      "Class 13 - Precision: 0.9666666666666667, Recall: 0.9666666666666667, F1 Score: 0.9666666666666667, Accuracy: 0.9955555555555555\n",
      "TTP: 29, TTN: 419, TFP: 1, TFN: 1\n",
      "\n",
      "Class 14 - Precision: 0.9354838709677419, Recall: 0.9666666666666667, F1 Score: 0.9508196721311476, Accuracy: 0.9933333333333333\n",
      "TTP: 29, TTN: 418, TFP: 2, TFN: 1\n",
      "\n",
      "Class 15 - Precision: 0.9666666666666667, Recall: 0.9666666666666667, F1 Score: 0.9666666666666667, Accuracy: 0.9955555555555555\n",
      "TTP: 29, TTN: 419, TFP: 1, TFN: 1\n",
      "\n",
      "Average Precision: 0.944700916378881\n",
      "Average Recall: 0.9422222222222223\n",
      "Average F1 Score: 0.9416299571559039\n",
      "Average Accuracy: 0.9922962962962962\n"
     ]
    }
   ],
   "source": [
    "#\"Performance Matrix Calculation\"\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "num_classes = conf_matrix.shape[0]\n",
    "\n",
    "class_metrics = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "    true_positives = conf_matrix[i, i]\n",
    "    false_positives = np.sum(conf_matrix[:, i]) - true_positives\n",
    "    false_negatives = np.sum(conf_matrix[i, :]) - true_positives\n",
    "\n",
    "    true_negatives = np.sum(conf_matrix) - true_positives - false_positives - false_negatives\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "    if precision == 0 and recall == 0:\n",
    "        f1_score = 0.0\n",
    "    else:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    accuracy = (true_positives + true_negatives) / np.sum(conf_matrix)\n",
    "\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1_score)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    class_metrics.append({\n",
    "        'Class': i + 1,\n",
    "        'True Positives': true_positives,\n",
    "        'True Negatives': true_negatives,\n",
    "        'False Positives': false_positives,\n",
    "        'False Negatives': false_negatives,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1_score,\n",
    "        'Accuracy': accuracy\n",
    "    })\n",
    "\n",
    "average_precision = sum(precisions) / len(precisions)\n",
    "average_recall = sum(recalls) / len(recalls)\n",
    "average_f1_score = sum(f1_scores) / len(f1_scores)\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "print(\"Class Metrics:\")\n",
    "for metrics in class_metrics:\n",
    "    print(f\"Class {metrics['Class']} - Precision: {metrics['Precision']}, Recall: {metrics['Recall']}, F1 Score: {metrics['F1 Score']}, Accuracy: {metrics['Accuracy']}\")\n",
    "    print(f\"TTP: {metrics['True Positives']}, TTN: {metrics['True Negatives']}, TFP: {metrics['False Positives']}, TFN: {metrics['False Negatives']}\")\n",
    "    print(\"\")\n",
    "\n",
    "print(\"Average Precision:\", average_precision)\n",
    "print(\"Average Recall:\", average_recall)\n",
    "print(\"Average F1 Score:\", average_f1_score)\n",
    "print(\"Average Accuracy:\", average_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-27T13:11:22.965094Z",
     "iopub.status.busy": "2023-09-27T13:11:22.964716Z",
     "iopub.status.idle": "2023-09-27T13:11:23.006214Z",
     "shell.execute_reply": "2023-09-27T13:11:23.004695Z",
     "shell.execute_reply.started": "2023-09-27T13:11:22.965065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Class TTP  TTN TFP TFN  Precision    Recall  F1 Score  Accuracy\n",
      "0          ADMIN  23  418   2   7   0.920000  0.766667  0.836364  0.980000\n",
      "1          ARCHI  30  420   0   0   1.000000  1.000000  1.000000  1.000000\n",
      "2     AUDITORIUM  26  419   1   4   0.962963  0.866667  0.912281  0.988889\n",
      "3    BANGABANDHU  30  417   3   0   0.909091  1.000000  0.952381  0.993333\n",
      "4           CAFE  27  420   0   3   1.000000  0.900000  0.947368  0.993333\n",
      "5     CHIROKUMAR  30  420   0   0   1.000000  1.000000  1.000000  1.000000\n",
      "6          CIVIL  28  416   4   2   0.875000  0.933333  0.903226  0.986667\n",
      "7        CSE DAY  30  415   5   0   0.857143  1.000000  0.923077  0.988889\n",
      "8            EEE  29  419   1   1   0.966667  0.966667  0.966667  0.995556\n",
      "9          HAMID  30  416   4   0   0.882353  1.000000  0.937500  0.991111\n",
      "10       LIBRARY  28  419   1   2   0.965517  0.933333  0.949153  0.993333\n",
      "11      SHAHIDUL  26  419   1   4   0.962963  0.866667  0.912281  0.988889\n",
      "12      TIN SHED  29  419   1   1   0.966667  0.966667  0.966667  0.995556\n",
      "13           URP  29  418   2   1   0.935484  0.966667  0.950820  0.993333\n",
      "14  WELDING SHOP  29  419   1   1   0.966667  0.966667  0.966667  0.995556\n",
      "15       Average                    0.944701  0.942222  0.941630  0.992296\n"
     ]
    }
   ],
   "source": [
    "#\"Results Visualization\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "num_classes = conf_matrix.shape[0]\n",
    "\n",
    "class_names = [\n",
    "    'ADMIN', 'ARCHI', 'AUDITORIUM', 'BANGABANDHU', 'CAFE',\n",
    "    'CHIROKUMAR', 'CIVIL', 'CSE DAY', 'EEE', 'HAMID',\n",
    "    'LIBRARY', 'SHAHIDUL', 'TIN SHED', 'URP', 'WELDING SHOP'\n",
    "]\n",
    "\n",
    "class_metrics = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "    true_positives = conf_matrix[i, i]\n",
    "    false_positives = np.sum(conf_matrix[:, i]) - true_positives\n",
    "    false_negatives = np.sum(conf_matrix[i, :]) - true_positives\n",
    "\n",
    "    true_negatives = np.sum(conf_matrix) - true_positives - false_positives - false_negatives\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "    if precision == 0 and recall == 0:\n",
    "        f1_score = 0.0\n",
    "    else:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    accuracy = (true_positives + true_negatives) / np.sum(conf_matrix)\n",
    "\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1_score)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    class_metrics.append({\n",
    "        'Class': class_names[i],\n",
    "        'TTP': true_positives,\n",
    "        'TTN': true_negatives,\n",
    "        'TFP': false_positives,\n",
    "        'TFN': false_negatives,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1_score,\n",
    "        'Accuracy': accuracy\n",
    "    })\n",
    "\n",
    "average_precision = sum(precisions) / len(precisions)\n",
    "average_recall = sum(recalls) / len(recalls)\n",
    "average_f1_score = sum(f1_scores) / len(f1_scores)\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "class_metrics.append({\n",
    "    'Class': 'Average',\n",
    "    'TTP': '',\n",
    "    'TTN': '',\n",
    "    'TFP': '',\n",
    "    'TFN': '',\n",
    "    'Precision': average_precision,\n",
    "    'Recall': average_recall,\n",
    "    'F1 Score': average_f1_score,\n",
    "    'Accuracy': average_accuracy\n",
    "})\n",
    "\n",
    "metrics_df = pd.DataFrame(class_metrics)\n",
    "\n",
    "metrics_df = metrics_df[['Class', 'TTP', 'TTN', 'TFP', 'TFN', 'Precision', 'Recall', 'F1 Score', 'Accuracy']]\n",
    "\n",
    "print(metrics_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
